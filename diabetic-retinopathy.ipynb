{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a909b08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T05:06:54.967381Z",
     "iopub.status.busy": "2024-09-07T05:06:54.967015Z",
     "iopub.status.idle": "2024-09-07T05:06:54.977855Z",
     "shell.execute_reply": "2024-09-07T05:06:54.977035Z"
    },
    "papermill": {
     "duration": 0.016708,
     "end_time": "2024-09-07T05:06:54.979794",
     "exception": false,
     "start_time": "2024-09-07T05:06:54.963086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications import EfficientNetV2S, DenseNet201\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, concatenate, Input, BatchNormalization\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import cv2\n",
    "# import albumentations as A\n",
    "\n",
    "# # Load and preprocess data\n",
    "# train_df = pd.read_csv('/kaggle/input/aptos2019-blindness-detection/train.csv')\n",
    "# train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
    "# train_df['id_code'] = train_df['id_code'].apply(lambda x: f\"{x}.png\")\n",
    "\n",
    "# # Label encoding\n",
    "# le = LabelEncoder()\n",
    "# train_df['diagnosis'] = le.fit_transform(train_df['diagnosis'])\n",
    "\n",
    "# def preprocess_image(image_path, target_size=(380, 380)):\n",
    "#     img = cv2.imread(image_path)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     # Apply CLAHE\n",
    "#     lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "#     l, a, b = cv2.split(lab)\n",
    "#     clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "#     cl = clahe.apply(l)\n",
    "#     limg = cv2.merge((cl,a,b))\n",
    "#     img = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "#     # Resize\n",
    "#     img = cv2.resize(img, target_size)\n",
    "    \n",
    "#     return img  # Return uint8 image\n",
    "\n",
    "# # Augmentation pipeline\n",
    "# aug_pipeline = A.Compose([\n",
    "#     A.RandomRotate90(),\n",
    "#     A.Flip(),\n",
    "#     A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45),\n",
    "#     A.OneOf([\n",
    "#         A.OpticalDistortion(p=0.3),\n",
    "#         A.GridDistortion(p=0.1),\n",
    "#         A.ElasticTransform(p=0.3),\n",
    "#     ], p=0.2),\n",
    "#     A.OneOf([\n",
    "#         A.GaussNoise(),\n",
    "#         A.ISONoise(),\n",
    "#         A.MultiplicativeNoise(),\n",
    "#     ], p=0.2),\n",
    "#     A.OneOf([\n",
    "#         A.MotionBlur(p=0.2),\n",
    "#         A.MedianBlur(blur_limit=3, p=0.1),\n",
    "#         A.Blur(blur_limit=3, p=0.1),\n",
    "#     ], p=0.2),\n",
    "#     A.OneOf([\n",
    "#         A.Sharpen(),\n",
    "#         A.Emboss(),\n",
    "#         A.RandomBrightnessContrast(),\n",
    "#     ], p=0.3),\n",
    "#     A.HueSaturationValue(p=0.3),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "\n",
    "# def custom_generator(dataframe, batch_size, augment=True, shuffle=True):\n",
    "#     while True:\n",
    "#         if shuffle:\n",
    "#             dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "#         for start in range(0, len(dataframe), batch_size):\n",
    "#             end = min(start + batch_size, len(dataframe))\n",
    "#             batch_df = dataframe.iloc[start:end]\n",
    "            \n",
    "#             batch_images = []\n",
    "#             batch_labels = []\n",
    "            \n",
    "#             for _, row in batch_df.iterrows():\n",
    "#                 img_path = f\"/kaggle/input/aptos2019-blindness-detection/train_images/{row['id_code']}\"\n",
    "#                 img = preprocess_image(img_path)\n",
    "                \n",
    "#                 if augment:\n",
    "#                     augmented = aug_pipeline(image=img)\n",
    "#                     img = augmented['image']\n",
    "#                 else:\n",
    "#                     img = aug_pipeline(image=img)['image']  # Only normalize\n",
    "                \n",
    "#                 batch_images.append(img)\n",
    "#                 batch_labels.append(row['diagnosis'])\n",
    "            \n",
    "#             yield np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "# # Create model\n",
    "# def create_model(input_shape=(380, 380, 3), num_classes=5):\n",
    "#     input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "#     # EfficientNetV2S\n",
    "#     base_model_1 = EfficientNetV2S(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "#     x1 = base_model_1.output\n",
    "#     x1 = GlobalAveragePooling2D()(x1)\n",
    "#     x1 = BatchNormalization()(x1)\n",
    "#     x1 = Dropout(0.5)(x1)\n",
    "#     x1 = Dense(512, activation='relu')(x1)\n",
    "#     x1 = BatchNormalization()(x1)\n",
    "#     x1 = Dropout(0.3)(x1)\n",
    "    \n",
    "#     # DenseNet201\n",
    "#     base_model_2 = DenseNet201(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "#     x2 = base_model_2.output\n",
    "#     x2 = GlobalAveragePooling2D()(x2)\n",
    "#     x2 = BatchNormalization()(x2)\n",
    "#     x2 = Dropout(0.5)(x2)\n",
    "#     x2 = Dense(512, activation='relu')(x2)\n",
    "#     x2 = BatchNormalization()(x2)\n",
    "#     x2 = Dropout(0.3)(x2)\n",
    "    \n",
    "#     # Combine outputs\n",
    "#     combined = concatenate([x1, x2])\n",
    "#     combined = Dense(256, activation='relu')(combined)\n",
    "#     combined = BatchNormalization()(combined)\n",
    "#     combined = Dropout(0.3)(combined)\n",
    "#     output = Dense(num_classes, activation='softmax')(combined)\n",
    "    \n",
    "#     model = Model(inputs=input_tensor, outputs=output)\n",
    "#     return model\n",
    "\n",
    "# # Implement k-fold cross-validation\n",
    "# n_splits = 2\n",
    "# skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['diagnosis']), 1):\n",
    "#     print(f\"Training Fold {fold}\")\n",
    "    \n",
    "#     train_fold = train_df.iloc[train_idx]\n",
    "#     val_fold = train_df.iloc[val_idx]\n",
    "    \n",
    "#     model = create_model()\n",
    "    \n",
    "#     # Compile model\n",
    "#     optimizer = Adam(learning_rate=0.0001)\n",
    "#     model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "#     # Callbacks\n",
    "#     callbacks = [\n",
    "#         EarlyStopping(patience=10, restore_best_weights=True),\n",
    "#         ModelCheckpoint(f'best_model_fold_{fold}.keras', save_best_only=True),\n",
    "#         ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6)\n",
    "#     ]\n",
    "    \n",
    "#     # Train model\n",
    "#     batch_size = 16\n",
    "#     train_generator = custom_generator(train_fold, batch_size)\n",
    "#     val_generator = custom_generator(val_fold, batch_size, augment=False, shuffle=False)\n",
    "    \n",
    "#     history = model.fit(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=len(train_fold) // batch_size,\n",
    "#         validation_data=val_generator,\n",
    "#         validation_steps=len(val_fold) // batch_size,\n",
    "#         epochs=100,\n",
    "#         callbacks=callbacks,\n",
    "#         verbose=2\n",
    "#     )\n",
    "    \n",
    "#     # Print fold results\n",
    "#     print(f\"Fold {fold} - Best validation accuracy: {max(history.history['val_accuracy'])}\")\n",
    "\n",
    "# # After all folds, you can ensemble the models for final predictions\n",
    "# print(\"Training completed for all folds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9bc5e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T05:06:54.985609Z",
     "iopub.status.busy": "2024-09-07T05:06:54.985323Z",
     "iopub.status.idle": "2024-09-07T06:55:45.372837Z",
     "shell.execute_reply": "2024-09-07T06:55:45.371458Z"
    },
    "papermill": {
     "duration": 6530.394207,
     "end_time": "2024-09-07T06:55:45.376309",
     "exception": false,
     "start_time": "2024-09-07T05:06:54.982102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Training Fold 1\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n",
      "\u001b[1m82420632/82420632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725685890.587673      65 service.cc:145] XLA service 0x7c2148005110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1725685890.587727      65 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "2024-09-07 05:20:41.539545: E external/local_xla/xla/service/slow_operation_alarm.cc:65] \n",
      "********************************\n",
      "[Compiling module a_inference_one_step_on_data_235599__.163720] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725686459.521716      65 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_210', 8 bytes spill stores, 68 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_14', 28 bytes spill stores, 28 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_15', 36 bytes spill stores, 36 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_16', 4 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_17', 8 bytes spill stores, 64 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1322', 28 bytes spill stores, 28 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1319', 40 bytes spill stores, 40 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1315', 40 bytes spill stores, 40 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_reduce_window_fusion_1', 60 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2024-09-07 05:21:00.168201: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2m18.628810169s\n",
      "\n",
      "********************************\n",
      "[Compiling module a_inference_one_step_on_data_235599__.163720] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n",
      "I0000 00:00:1725686460.184967      65 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 - 986s - 9s/step - accuracy: 0.5027 - loss: 1.5110 - val_accuracy: 0.6168 - val_loss: 0.9553 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1725687213.560455      65 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1512', 344 bytes spill stores, 316 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1511', 192 bytes spill stores, 192 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1510', 292 bytes spill stores, 292 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1509', 300 bytes spill stores, 300 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1508', 308 bytes spill stores, 308 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1507', 316 bytes spill stores, 316 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1505', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1504', 12 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_32', 32 bytes spill stores, 32 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_compare_reduce_fusion_6', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_199', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_200', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_201', 12 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_fusion_70', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1', 64 bytes spill stores, 64 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion', 364 bytes spill stores, 364 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_1', 364 bytes spill stores, 364 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1038', 20 bytes spill stores, 20 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1035', 20 bytes spill stores, 20 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1034', 16 bytes spill stores, 16 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1031', 16 bytes spill stores, 16 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1030', 12 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1027', 12 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1026', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1023', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1022', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1019', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1018', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_969', 12 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_966', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_963', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_960', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_959', 4 bytes spill stores, 4 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_956', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-09-07 05:33:34.216980: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3m14.737882866s\n",
      "\n",
      "********************************\n",
      "[Compiling module a_inference_one_step_on_data_235599__.163720] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n",
      "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 - 607s - 5s/step - accuracy: 0.7143 - loss: 1.0946 - val_accuracy: 0.5714 - val_loss: 0.8386 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "114/114 - 196s - 2s/step - accuracy: 0.6338 - loss: 1.1382 - val_accuracy: 0.7434 - val_loss: 0.7204 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "114/114 - 6s - 52ms/step - accuracy: 0.8571 - loss: 0.6524 - val_accuracy: 0.8571 - val_loss: 0.4012 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "114/114 - 201s - 2s/step - accuracy: 0.6771 - loss: 1.0291 - val_accuracy: 0.6721 - val_loss: 0.8056 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 0.8571 - loss: 0.2888 - val_accuracy: 0.8571 - val_loss: 1.0308 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "114/114 - 188s - 2s/step - accuracy: 0.6870 - loss: 0.9418 - val_accuracy: 0.7615 - val_loss: 0.6568 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 0.7143 - loss: 1.5937 - val_accuracy: 0.8571 - val_loss: 0.4995 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "114/114 - 187s - 2s/step - accuracy: 0.7012 - loss: 0.9070 - val_accuracy: 0.7758 - val_loss: 0.5946 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 1.0000 - loss: 0.2374 - val_accuracy: 0.7143 - val_loss: 0.7059 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "114/114 - 186s - 2s/step - accuracy: 0.7100 - loss: 0.8771 - val_accuracy: 0.7939 - val_loss: 0.5926 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 0.8571 - loss: 0.3656 - val_accuracy: 0.8571 - val_loss: 0.5135 - learning_rate: 5.0000e-05\n",
      "Epoch 13/20\n",
      "114/114 - 187s - 2s/step - accuracy: 0.7253 - loss: 0.8084 - val_accuracy: 0.8103 - val_loss: 0.5302 - learning_rate: 5.0000e-05\n",
      "Epoch 14/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 0.7143 - loss: 0.9826 - val_accuracy: 0.8571 - val_loss: 0.4997 - learning_rate: 5.0000e-05\n",
      "Epoch 15/20\n",
      "114/114 - 186s - 2s/step - accuracy: 0.7357 - loss: 0.7831 - val_accuracy: 0.8120 - val_loss: 0.5035 - learning_rate: 5.0000e-05\n",
      "Epoch 16/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 0.7143 - loss: 0.6742 - val_accuracy: 0.8571 - val_loss: 0.4411 - learning_rate: 5.0000e-05\n",
      "Epoch 17/20\n",
      "114/114 - 186s - 2s/step - accuracy: 0.7319 - loss: 0.7827 - val_accuracy: 0.8196 - val_loss: 0.4840 - learning_rate: 5.0000e-05\n",
      "Epoch 18/20\n",
      "114/114 - 8s - 67ms/step - accuracy: 0.8571 - loss: 0.6308 - val_accuracy: 0.8571 - val_loss: 0.2745 - learning_rate: 5.0000e-05\n",
      "Epoch 19/20\n",
      "114/114 - 185s - 2s/step - accuracy: 0.7357 - loss: 0.7577 - val_accuracy: 0.7977 - val_loss: 0.5089 - learning_rate: 5.0000e-05\n",
      "Epoch 20/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 0.4286 - loss: 0.9315 - val_accuracy: 0.8571 - val_loss: 0.5865 - learning_rate: 5.0000e-05\n",
      "Fold 1 - Best validation accuracy: 0.8571428656578064\n",
      "Training Fold 2\n",
      "Epoch 1/20\n",
      "114/114 - 858s - 8s/step - accuracy: 0.5000 - loss: 1.4879 - val_accuracy: 0.6464 - val_loss: 1.0532 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "114/114 - 479s - 4s/step - accuracy: 0.2857 - loss: 1.9909 - val_accuracy: 0.7143 - val_loss: 1.0155 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "114/114 - 201s - 2s/step - accuracy: 0.6261 - loss: 1.1267 - val_accuracy: 0.6721 - val_loss: 1.0619 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 0.4286 - loss: 1.2897 - val_accuracy: 0.4286 - val_loss: 2.0556 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "114/114 - 207s - 2s/step - accuracy: 0.6557 - loss: 1.0573 - val_accuracy: 0.7473 - val_loss: 0.7845 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 0.7143 - loss: 0.5663 - val_accuracy: 0.5714 - val_loss: 1.2322 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "114/114 - 208s - 2s/step - accuracy: 0.6826 - loss: 0.9812 - val_accuracy: 0.7763 - val_loss: 0.7465 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "114/114 - 6s - 52ms/step - accuracy: 1.0000 - loss: 0.4618 - val_accuracy: 0.7143 - val_loss: 0.6389 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "114/114 - 202s - 2s/step - accuracy: 0.7133 - loss: 0.8609 - val_accuracy: 0.7867 - val_loss: 0.6474 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 0.8571 - loss: 0.6040 - val_accuracy: 0.7143 - val_loss: 1.0636 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "114/114 - 205s - 2s/step - accuracy: 0.7237 - loss: 0.8462 - val_accuracy: 0.7840 - val_loss: 0.5958 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 0.8571 - loss: 0.4417 - val_accuracy: 0.7143 - val_loss: 0.7633 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "114/114 - 206s - 2s/step - accuracy: 0.7396 - loss: 0.7726 - val_accuracy: 0.7884 - val_loss: 0.5831 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 0.8571 - loss: 0.6137 - val_accuracy: 0.5714 - val_loss: 1.0381 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "114/114 - 198s - 2s/step - accuracy: 0.7346 - loss: 0.7532 - val_accuracy: 0.7895 - val_loss: 0.5969 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "114/114 - 6s - 52ms/step - accuracy: 0.7143 - loss: 1.0639 - val_accuracy: 0.8571 - val_loss: 0.4886 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "114/114 - 200s - 2s/step - accuracy: 0.7445 - loss: 0.7367 - val_accuracy: 0.8059 - val_loss: 0.5640 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 1.0000 - loss: 0.2379 - val_accuracy: 0.8571 - val_loss: 0.6793 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "114/114 - 201s - 2s/step - accuracy: 0.7467 - loss: 0.7428 - val_accuracy: 0.8120 - val_loss: 0.5468 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "114/114 - 1s - 5ms/step - accuracy: 0.8571 - loss: 0.3244 - val_accuracy: 0.7143 - val_loss: 0.9507 - learning_rate: 1.0000e-04\n",
      "Fold 2 - Best validation accuracy: 0.8571428656578064\n",
      "Training completed for all folds.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetV2S, DenseNet201\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, concatenate, Input, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# Use GPU if available, otherwise use CPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Using GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Load and preprocess data\n",
    "train_df = pd.read_csv('/kaggle/input/aptos2019-blindness-detection/train.csv')\n",
    "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
    "train_df['id_code'] = train_df['id_code'].apply(lambda x: f\"{x}.png\")\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "train_df['diagnosis'] = le.fit_transform(train_df['diagnosis'])\n",
    "\n",
    "def preprocess_image(image_path, label):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, (380, 380))\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img, label\n",
    "\n",
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_hue(image, max_delta=0.2)\n",
    "    return image, label\n",
    "\n",
    "def create_dataset(dataframe, batch_size, is_training=True):\n",
    "    image_paths = tf.constant([f\"/kaggle/input/aptos2019-blindness-detection/train_images/{filename}\" for filename in dataframe['id_code']])\n",
    "    labels = tf.constant(dataframe['diagnosis'].values, dtype=tf.int32)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(buffer_size=len(dataframe))\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def create_model(input_shape=(380, 380, 3), num_classes=5):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "    base_model_1 = EfficientNetV2S(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "    x1 = GlobalAveragePooling2D()(base_model_1.output)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "    x1 = Dense(512, activation='relu')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    \n",
    "    base_model_2 = DenseNet201(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "    x2 = GlobalAveragePooling2D()(base_model_2.output)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Dropout(0.5)(x2)\n",
    "    x2 = Dense(512, activation='relu')(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "    \n",
    "    combined = concatenate([x1, x2])\n",
    "    combined = Dense(256, activation='relu')(combined)\n",
    "    combined = BatchNormalization()(combined)\n",
    "    combined = Dropout(0.3)(combined)\n",
    "    output = Dense(num_classes, activation='softmax')(combined)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Implement k-fold cross-validation\n",
    "n_splits = 2\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['diagnosis']), 1):\n",
    "    print(f\"Training Fold {fold}\")\n",
    "    \n",
    "    train_fold = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    model = create_model()\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=15, restore_best_weights=True),\n",
    "        ModelCheckpoint(f'best_model_fold_{fold}.keras', save_best_only=True),\n",
    "        ReduceLROnPlateau(factor=0.5, patience=7, min_lr=1e-6)\n",
    "    ]\n",
    "    \n",
    "    # Create datasets\n",
    "    batch_size = 16  # Adjust based on your GPU memory\n",
    "    train_dataset = create_dataset(train_fold, batch_size)\n",
    "    val_dataset = create_dataset(val_fold, batch_size, is_training=False)\n",
    "    \n",
    "    # Train model\n",
    "    try:\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            epochs=20,\n",
    "            callbacks=callbacks,\n",
    "            steps_per_epoch=len(train_fold) // batch_size,\n",
    "            validation_steps=len(val_fold) // batch_size,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Print fold results\n",
    "        print(f\"Fold {fold} - Best validation accuracy: {max(history.history['val_accuracy'])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during training fold {fold}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"Training completed for all folds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff2b3d",
   "metadata": {
    "papermill": {
     "duration": 0.015478,
     "end_time": "2024-09-07T06:55:45.407710",
     "exception": false,
     "start_time": "2024-09-07T06:55:45.392232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 875431,
     "sourceId": 14774,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6537.319034,
   "end_time": "2024-09-07T06:55:49.558981",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-07T05:06:52.239947",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
